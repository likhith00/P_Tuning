{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-22T07:18:46.745774Z","iopub.status.busy":"2024-02-22T07:18:46.745497Z","iopub.status.idle":"2024-02-22T07:19:01.180734Z","shell.execute_reply":"2024-02-22T07:19:01.179489Z","shell.execute_reply.started":"2024-02-22T07:18:46.745749Z"},"trusted":true},"outputs":[],"source":["!pip install -q peft transformers datasets evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:01.182877Z","iopub.status.busy":"2024-02-22T07:19:01.182565Z","iopub.status.idle":"2024-02-22T07:19:01.443610Z","shell.execute_reply":"2024-02-22T07:19:01.442766Z","shell.execute_reply.started":"2024-02-22T07:19:01.182848Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7c3384d5fa6449487b04c3b03adc922","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:13.230883Z","iopub.status.busy":"2024-02-22T07:19:13.229976Z","iopub.status.idle":"2024-02-22T07:19:34.586149Z","shell.execute_reply":"2024-02-22T07:19:34.585368Z","shell.execute_reply.started":"2024-02-22T07:19:13.230851Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-22 07:19:21.200056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-22 07:19:21.200183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-22 07:19:21.359845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    TrainingArguments,\n","    Trainer,\n",")\n","from peft import (\n","    get_peft_config,\n","    get_peft_model,\n","    get_peft_model_state_dict,\n","    set_peft_model_state_dict,\n","    PeftType,\n","    PromptEncoderConfig,\n",")\n","from datasets import load_dataset\n","import evaluate\n","import torch\n","\n","model_name_or_path = \"roberta-large\"\n","task = \"mrpc\"\n","num_epochs = 20\n","lr = 1e-3\n","batch_size = 32"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:34.588775Z","iopub.status.busy":"2024-02-22T07:19:34.587978Z","iopub.status.idle":"2024-02-22T07:19:37.360544Z","shell.execute_reply":"2024-02-22T07:19:37.359691Z","shell.execute_reply.started":"2024-02-22T07:19:34.588740Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b77406297d94d7ca73ff455581232d1","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c361f23df09343c8863673552e6305b3","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"580312469ae54b1f9df4c316ed90d1be","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef5d6bf106e2407cadee1dedd29e9437","version_major":2,"version_minor":0},"text/plain":["Downloading data: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12e326590b1447d4916adf161a44400b","version_major":2,"version_minor":0},"text/plain":["Downloading data: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9567441b76146dda352ccfb9ac65819","version_major":2,"version_minor":0},"text/plain":["Downloading data: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cf92ff424174dec88389e824a64bfba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n"," 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n"," 'label': 1,\n"," 'idx': 0}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset = load_dataset(\"glue\", task)\n","dataset[\"train\"][0]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:37.361986Z","iopub.status.busy":"2024-02-22T07:19:37.361685Z","iopub.status.idle":"2024-02-22T07:19:38.188076Z","shell.execute_reply":"2024-02-22T07:19:38.187261Z","shell.execute_reply.started":"2024-02-22T07:19:37.361961Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"223283b5d49d4cb99f2801bd9a02f5da","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["metric = evaluate.load(\"glue\", task)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:38.190400Z","iopub.status.busy":"2024-02-22T07:19:38.190096Z","iopub.status.idle":"2024-02-22T07:19:38.196252Z","shell.execute_reply":"2024-02-22T07:19:38.195379Z","shell.execute_reply.started":"2024-02-22T07:19:38.190374Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:38.197510Z","iopub.status.busy":"2024-02-22T07:19:38.197267Z","iopub.status.idle":"2024-02-22T07:19:40.234533Z","shell.execute_reply":"2024-02-22T07:19:40.233560Z","shell.execute_reply.started":"2024-02-22T07:19:38.197489Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2ae0b2512d14a10adba4ca65c64d459","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"762156de08af456bbef59c64452c22cb","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"657ffb66971d4999a8fb57ffd5d972fa","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce560999e8a74ca88f9c87fa27cfbecf","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35bc08c860ba45418bd2ffaf48031b3f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n","    padding_side = \"left\"\n","else:\n","    padding_side = \"right\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n","if getattr(tokenizer, \"pad_token_id\") is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","\n","def tokenize_function(examples):\n","    # max_length=None => use the model max length (it's actually the default)\n","    outputs = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=None)\n","    return outputs"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:40.236148Z","iopub.status.busy":"2024-02-22T07:19:40.235748Z","iopub.status.idle":"2024-02-22T07:19:41.030191Z","shell.execute_reply":"2024-02-22T07:19:41.029400Z","shell.execute_reply.started":"2024-02-22T07:19:40.236108Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebca1e86e293449091c8cca6b34ed9ad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5026dc58751c4e31ba5e34ee21ff1e59","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29888b8aa06348a1bebd2676bcbfe9f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = dataset.map(\n","    tokenize_function,\n","    batched=True,\n","    remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n",")\n","\n","tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:41.031694Z","iopub.status.busy":"2024-02-22T07:19:41.031384Z","iopub.status.idle":"2024-02-22T07:19:41.035916Z","shell.execute_reply":"2024-02-22T07:19:41.035024Z","shell.execute_reply.started":"2024-02-22T07:19:41.031669Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:41.037491Z","iopub.status.busy":"2024-02-22T07:19:41.037162Z","iopub.status.idle":"2024-02-22T07:19:41.050575Z","shell.execute_reply":"2024-02-22T07:19:41.049756Z","shell.execute_reply.started":"2024-02-22T07:19:41.037461Z"},"trusted":true},"outputs":[],"source":["peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=20, encoder_hidden_size=128)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:19:41.052243Z","iopub.status.busy":"2024-02-22T07:19:41.051891Z","iopub.status.idle":"2024-02-22T07:19:47.965074Z","shell.execute_reply":"2024-02-22T07:19:47.964113Z","shell.execute_reply.started":"2024-02-22T07:19:41.052207Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a1feceb80c049aea45d649b31f6a1f1","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["trainable params: 1,351,938 || all params: 356,713,732 || trainable%: 0.3789980252288129\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:20:59.581954Z","iopub.status.busy":"2024-02-22T07:20:59.581187Z","iopub.status.idle":"2024-02-22T07:20:59.590830Z","shell.execute_reply":"2024-02-22T07:20:59.589696Z","shell.execute_reply.started":"2024-02-22T07:20:59.581918Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"outputs/roberta-large-peft-p-tuning\",\n","    learning_rate=1e-3,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:21:00.017093Z","iopub.status.busy":"2024-02-22T07:21:00.016092Z","iopub.status.idle":"2024-02-22T07:38:46.295669Z","shell.execute_reply":"2024-02-22T07:38:46.294689Z","shell.execute_reply.started":"2024-02-22T07:21:00.017057Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='580' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [580/580 17:44, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.609398</td>\n","      <td>0.679420</td>\n","      <td>0.801579</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.666898</td>\n","      <td>0.673043</td>\n","      <td>0.801966</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.614854</td>\n","      <td>0.681739</td>\n","      <td>0.804278</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.690202</td>\n","      <td>0.665507</td>\n","      <td>0.799025</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.590705</td>\n","      <td>0.696812</td>\n","      <td>0.806368</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.615271</td>\n","      <td>0.680580</td>\n","      <td>0.802580</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>0.594967</td>\n","      <td>0.693913</td>\n","      <td>0.807860</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>0.605051</td>\n","      <td>0.689855</td>\n","      <td>0.807346</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.620900</td>\n","      <td>0.591118</td>\n","      <td>0.697391</td>\n","      <td>0.808931</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.620900</td>\n","      <td>0.591311</td>\n","      <td>0.697391</td>\n","      <td>0.808229</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=580, training_loss=0.6159444874730603, metrics={'train_runtime': 1065.3397, 'train_samples_per_second': 34.43, 'train_steps_per_second': 0.544, 'total_flos': 5639290068053376.0, 'train_loss': 0.6159444874730603, 'epoch': 10.0})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:38:46.297483Z","iopub.status.busy":"2024-02-22T07:38:46.297174Z","iopub.status.idle":"2024-02-22T07:38:48.577423Z","shell.execute_reply":"2024-02-22T07:38:48.576316Z","shell.execute_reply.started":"2024-02-22T07:38:46.297459Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c09c9006e34547e7855f89e412fcf602","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/4.29M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/likhith231/roberta-large-peft-p-tuning/commit/e61b2329a53dea2a09d24dcafa5af3fb0b1d4b77', commit_message='Upload model', commit_description='', oid='e61b2329a53dea2a09d24dcafa5af3fb0b1d4b77', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub(\"likhith231/roberta-large-peft-p-tuning\", use_auth_token=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:39:15.265080Z","iopub.status.busy":"2024-02-22T07:39:15.264423Z","iopub.status.idle":"2024-02-22T07:39:17.489108Z","shell.execute_reply":"2024-02-22T07:39:17.488119Z","shell.execute_reply.started":"2024-02-22T07:39:15.265049Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b827be0b34b447597a7b2c02bc6df20","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/431 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f74d99c6bfd437e82c561904ff4fe57","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/4.29M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from peft import PeftModel, PeftConfig\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","peft_model_id = \"likhith231/roberta-large-peft-p-tuning\"\n","config = PeftConfig.from_pretrained(peft_model_id)\n","inference_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n","tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n","model = PeftModel.from_pretrained(inference_model, peft_model_id)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T07:39:41.683405Z","iopub.status.busy":"2024-02-22T07:39:41.683018Z","iopub.status.idle":"2024-02-22T07:39:42.223097Z","shell.execute_reply":"2024-02-22T07:39:42.222159Z","shell.execute_reply.started":"2024-02-22T07:39:41.683377Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.2172,  0.1739]])\n","not equivalent: 40%\n","equivalent: 60%\n"]}],"source":["classes = [\"not equivalent\", \"equivalent\"]\n","\n","sentence1 = \"Coast redwood trees are the tallest trees on the planet and can grow over 300 feet tall.\"\n","sentence2 = \"The coast redwood trees, which can attain a height of over 300 feet, are the tallest trees on earth.\"\n","\n","inputs = tokenizer(sentence1, sentence2, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n","\n","with torch.no_grad():\n","    outputs = model(**inputs).logits\n","    print(outputs)\n","\n","paraphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\n","for i in range(len(classes)):\n","    print(f\"{classes[i]}: {int(round(paraphrased_text[i] * 100))}%\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
